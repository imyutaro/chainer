{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第3章 Chainerの使い方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 基本オブジェクト"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.1 Variable\n",
    "\n",
    "- 変数に入る実際のデータは配列\n",
    "- Variableの変数の演算結果もVariableの変数になる\n",
    "- dataという属性で参照できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 42.], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import Variable, optimizers, serializers, utils\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import chainer.computational_graph as c\n",
    "from chainer.functions.loss.mean_squared_error import mean_squared_error\n",
    "\n",
    "\n",
    "x1 = Variable(np.array([1], dtype=np.float32))\n",
    "x2 = Variable(np.array([2], dtype=np.float32))\n",
    "x3 = Variable(np.array([3], dtype=np.float32))\n",
    "\n",
    "z = (x1-2*x2-1)**2+(x2*x3-1)**2+1\n",
    "z.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "- 順方向にいったん計算したことになるので、微分値を得るためには、逆向きの計算を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()\n",
    "x1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 20.], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 微分の式\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x_1}=2(x_1-2x_2-1)\\\\\n",
    "\\frac{\\partial z}{\\partial x_2}=-4(x_1-2x_2-1)+2x_3(x_2x_3-1)\\\\\n",
    "\\frac{\\partial z}{\\partial x_3}=2x_3(x_2x_3-1)\\\\\n",
    "$$\n",
    "<div style=\"text-align: center;\">\n",
    "$(x_1,x_2,x_3)=(1,2,3)$を代入すれば<br>　\n",
    "</div>\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x_1}=2\\times(1-2\\times2-1)=-8\\\\\n",
    "\\frac{\\partial z}{\\partial x_2}=-4\\times(1-2\\times2-1)+2\\times3(2\\times3-1)=46\\\\\n",
    "\\frac{\\partial z}{\\partial x_3}=2\\times3\\times(2\\times3-1)=20\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.2 Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.84147096], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(np.array([-1], dtype=np.float32))\n",
    "F.sin(x).data #sin関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2689414], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid(x).data #sigmoid関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "- $(\\,\\cos (x)\\,)’ = -\\sin(x)$ を確かめてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.87758255], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(np.array([-0.5], dtype=np.float32))\n",
    "z = F.cos(x)\n",
    "z.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.47942555], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.47942555], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-1)*F.sin(x).data # (cos(x))' = -sin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "- シグモイド関数についても$(\\;f'(x)=(1-f(x))\\;f(x)\\;)$を確かめてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.37754068], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(np.array([-0.5], dtype=np.float32))\n",
    "z = F.sigmoid(x)\n",
    "z.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.23500371], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.23500371], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((1-F.sigmoid(x))*F.sigmoid(x)).data # f'(x)=(1-f(x))*f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "- 変数が多次元である場合は関数の傾きの次元をあらかじめ教えておく必要がある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.54030228,  1.        ,  0.54030228], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(np.array([-1, 0, 1], dtype=np.float32))\n",
    "z = F.sin(x)\n",
    "z.grad = np.ones(3, dtype=np.float32)\n",
    "z.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## 3.2.3 links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = L.Linear(3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- パラメータは$W$と$b$\n",
    "- 最初に$W$には適当な値が$b$には0が入っている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.73528326, -0.42754531, -0.79784918],\n",
       "       [-0.3103115 ,  0.74695861, -0.09231593],\n",
       "       [ 0.22093138, -0.93409973,  0.30161089],\n",
       "       [ 0.65773547, -0.11706574, -0.79936308]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.W.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.b.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "- 入力はバッチ（データの集合）\n",
    "- 下の例は2つの3次元のベクトルを作って$\\;h\\;$に与えている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.],\n",
       "       [ 3.,  4.,  5.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(np.array(range(6)).astype(np.float32).reshape(2,3))\n",
    "x.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.02324367,  0.56232679, -0.33087796, -1.71579194],\n",
       "       [-7.90527678,  1.59532034, -1.56555033, -2.49187183]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = h(x)\n",
    "y.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正しく計算できているのかの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.02324367,  0.56232679, -0.33087796, -1.71579194],\n",
       "       [-7.90527678,  1.59532034, -1.56555033, -2.49187183]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = h.W.data\n",
    "x0 = x.data\n",
    "x0.dot(w.T) + h.b.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Chainクラス"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "class MyChain(Chain):\n",
    "    def __init__(self):\n",
    "        super(MyChain, self).__init__(\n",
    "            l1=L.Linear(4, 3),\n",
    "            l2=L.Linear(3, 3)\n",
    "        )\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        fv = self.fwd(x, y)\n",
    "        loss = F.mean_squared_error(fv, y)\n",
    "        return loss\n",
    "\n",
    "    def fwd(self, x, y):\n",
    "        return F.sigmoid(self.l1(x))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "```python\n",
    "model = MyChain() # モデルの生成\n",
    "optimizer = optimizers.SGD() # 最適化アルゴリズムの選択\n",
    "optimizer.setup(model) # アルゴリズムにモデルをセット\n",
    "\n",
    "model.zerograds() # 勾配の初期化\n",
    "loss = model(x, y) # 順方向に計算して誤差を算出\n",
    "loss.backward() # 逆方向の計算、勾配の計算\n",
    "optimizer.update() # パラメータの更新\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# +α　AND・OR・XORの論理演算を学習させてみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考\n",
    "[Chainerに入門、And/Or/Xorの実装 ](http://qiita.com/daisukelab/items/6ad3242eeba140023191)\n",
    "\n",
    "[chainerでニューラルネットを学んでみるよ(chainerでニューラルネット2)](http://hi-king.hatenablog.com/entry/2015/06/27/194630)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 層が1つの場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<AND: Before learning>>\n",
      "model says:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-28b7709ebfa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mand_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<<AND: Before learning>>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mand_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mand_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n<<AND: After Learning>>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mlearning_looper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mand_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mand_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-28b7709ebfa6>\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(model, optimizer, inputs, outputs)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0msum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0msum_accuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  %d & %d = %d (zero:%f one:%f)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;31m#mean_loss = sum_loss / len(inputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m#mean_accuracy = sum_accuracy / len(inputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "# And/Or/Xor classifier network example\n",
    "#\n",
    "# This is re-written version of:\n",
    "#   http://hi-king.hatenablog.com/entry/2015/06/27/194630\n",
    "# By following chainer introduction:\n",
    "#   http://docs.chainer.org/en/stable/tutorial/basic.html\n",
    "\n",
    "## Chainer cliche\n",
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import Function, Variable, optimizers, serializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "\n",
    "# Neural Network\n",
    "\n",
    "## Network definition\n",
    "class NN2x2x1dim(Chain):\n",
    "    def __init__(self):\n",
    "        super(NN2x2x1dim, self).__init__(\n",
    "            l = L.Linear(2, 2),\n",
    "        )\n",
    "    def __call__(self, x):\n",
    "        h = self.l(x)\n",
    "        return h\n",
    "\n",
    "# Sub routine\n",
    "\n",
    "## Utility: Summarize current results\n",
    "def summarize(model, optimizer, inputs, outputs):\n",
    "    sum_loss, sum_accuracy = 0, 0\n",
    "    print('model says:')\n",
    "    for i in range(len(inputs)):\n",
    "        x  = Variable(inputs[i].reshape(1,2).astype(np.float32))\n",
    "        t  = Variable(outputs[i].astype(np.int32))\n",
    "        y = model.predictor(x)\n",
    "        loss = model(x, t)\n",
    "        sum_loss += loss.data\n",
    "        sum_accuracy += model.accuracy.data\n",
    "        print('  %d & %d = %d (zero:%f one:%f)' % (x.data[0,0], x.data[0,1], np.argmax(y.data), y.data[0,0], y.data[0,1]))\n",
    "    #mean_loss = sum_loss / len(inputs)\n",
    "    #mean_accuracy = sum_accuracy / len(inputs)\n",
    "    #print sum_loss, sum_accuracy, mean_loss, mean_accuracy\n",
    "\n",
    "## Runs learning loop\n",
    "def learning_looper(model, optimizer, inputs, outputs, epoch_size):\n",
    "    augment_size = 100\n",
    "    for epoch in range(epoch_size):\n",
    "        print('epoch %d' % epoch)\n",
    "        for a in range(augment_size):\n",
    "            for i in range(len(inputs)):\n",
    "                x = Variable(inputs[i].reshape(1,2).astype(np.float32))\n",
    "                t = Variable(outputs[i].astype(np.int32))\n",
    "                optimizer.update(model, x, t)\n",
    "        summarize(model, optimizer, inputs, outputs)\n",
    "\n",
    "# Main\n",
    "## Test data\n",
    "inputs = np.array([[0., 0.], [0., 1.], [1., 0.], [1., 1.]], dtype=np.float32)\n",
    "and_outputs = np.array([[0], [0], [0], [1]], dtype=np.int32)\n",
    "or_outputs = np.array([[0], [1], [1], [1]], dtype=np.int32)\n",
    "xor_outputs = np.array([[0], [1], [1], [0]], dtype=np.int32)\n",
    "\n",
    "## AND Test --> will learn successfully\n",
    "## Model & Optimizer instance\n",
    "and_model = L.Classifier(NN2x2x1dim())\n",
    "optimizer = optimizers.SGD()\n",
    "# quicker) optimizer = optimizers.MomentumSGD(lr=0.01, momentum=0.9)\n",
    "optimizer.setup(and_model)\n",
    "print('<<AND: Before learning>>')\n",
    "summarize(and_model, optimizer, inputs, and_outputs)\n",
    "print('\\n<<AND: After Learning>>')\n",
    "learning_looper(and_model, optimizer, inputs, and_outputs, epoch_size = 5)\n",
    "\n",
    "## OR Test --> will learn successfully\n",
    "## Model & Optimizer instance\n",
    "or_model = L.Classifier(NN2x2x1dim())\n",
    "optimizer = optimizers.SGD()\n",
    "optimizer.setup(or_model)\n",
    "print('\\n---------\\n\\n<<OR: Before learning>>')\n",
    "summarize(or_model, optimizer, inputs, or_outputs)\n",
    "print('\\n<<OR: After Learning>>')\n",
    "learning_looper(or_model, optimizer, inputs, or_outputs, epoch_size = 5)\n",
    "\n",
    "## XOR Test --> will FAIL, single link is not enough for XOR\n",
    "## Model & Optimizer instance\n",
    "xor_model = L.Classifier(NN2x2x1dim())\n",
    "optimizer = optimizers.SGD()\n",
    "optimizer.setup(xor_model)\n",
    "print('\\n---------\\n\\n<<XOR: Before learning>>')\n",
    "summarize(xor_model, optimizer, inputs, xor_outputs)\n",
    "print('\\n<<XOR: After Learning>>')\n",
    "learning_looper(xor_model, optimizer, inputs, xor_outputs, epoch_size = 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 層が2つの場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<AND: Before learning>>\n",
      "\n",
      "<<AND: After Learning>>\n",
      "epoch 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9573fa068e83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#summarize(and_model, optimizer, inputs, and_outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n<<AND: After Learning>>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m \u001b[0mlearning_looper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mand_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mand_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m## OR Test --> will learn successfully\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-9573fa068e83>\u001b[0m in \u001b[0;36mlearning_looper\u001b[0;34m(model, optimizer, inputs, outputs, epoch_size)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzerograds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "# Chainer training: And/Or/Xor classifier network example with 2 links.\n",
    "#\n",
    "# This is re-written version of:\n",
    "#   http://hi-king.hatenablog.com/entry/2015/06/27/194630\n",
    "# By following chainer introduction:\n",
    "#   http://docs.chainer.org/en/stable/tutorial/basic.html\n",
    "\n",
    "## Chainer cliche\n",
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import Function, Variable, optimizers, serializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "\n",
    "import chainer.links as L\n",
    "\n",
    "# Neural Network\n",
    "\n",
    "## Network definition\n",
    "class NN2x2_2links(Chain):\n",
    "    def __init__(self):\n",
    "        super(NN2x2_2links, self).__init__(\n",
    "            l1 = L.Linear(2, 2),\n",
    "            l2 = L.Linear(2, 2),\n",
    "        )\n",
    "    def __call__(self, x, y):\n",
    "        fv = self.forward(x,y)\n",
    "        loss = F.mean_squared_error(fv,y)\n",
    "        return loss\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.l2(F.sigmoid(self.l1(x)))\n",
    "        \n",
    "\n",
    "# Sub routine\n",
    "\n",
    "## Utility: Summarize current results\n",
    "\"\"\"\n",
    "def summarize(model, optimizer, inputs, outputs):\n",
    "    sum_loss, sum_accuracy = 0, 0\n",
    "    print('model says:')\n",
    "    for i in range(len(inputs)):\n",
    "        x  = Variable(inputs[i].reshape(1,2).astype(np.float32))\n",
    "        t  = Variable(outputs[i].astype(np.int32))\n",
    "        y = model.predictor(x)\n",
    "        #loss = model(x, t)\n",
    "        #sum_loss += loss.data\n",
    "        #sum_accuracy += model.accuracy.data\n",
    "        print('  %d & %d = %d (zero:%f one:%f)' % (x.data[0,0], x.data[0,1], np.argmax(y.data), y.data[0,0], y.data[0,1]))\n",
    "    #mean_loss = sum_loss / len(inputs)\n",
    "    #mean_accuracy = sum_accuracy / len(inputs)\n",
    "    #print sum_loss, sum_accuracy, mean_loss, mean_accuracy\n",
    "\"\"\"\n",
    "## Runs learning loop\n",
    "def learning_looper(model, optimizer, inputs, outputs, epoch_size):\n",
    "    augment_size = 100\n",
    "    for epoch in range(epoch_size):\n",
    "        print('epoch %d' % epoch)\n",
    "        for a in range(augment_size):\n",
    "            for i in range(len(inputs)):\n",
    "                x = Variable(inputs[i].reshape(1,2).astype(np.float32))\n",
    "                t = Variable(outputs[i].astype(np.int32))\n",
    "                #optimizer.update(model, x, t)                \n",
    "                h = model.forward(x)\n",
    "                model.zerograds()\n",
    "                error = F.softmax_cross_entropy(h, t)\n",
    "                accuracy = F.accuracy(h, t)\n",
    "                error.backward()\n",
    "                optimizer.update()\n",
    "        #summarize(model, optimizer, inputs, outputs)\n",
    "        print('  %d & %d = %d (zero:%f one:%f)' % (x.data[0,0], x.data[0,1], np.argmax(h.data), h.data[0,0], h.data[0,1]))\n",
    "        \n",
    "\"\"\"\n",
    "## Runs XOR_learning loop\n",
    "def XOR_learning_looper(model, optimizer, inputs, outputs, epoch_size):\n",
    "    augment_size = 100\n",
    "    for epoch in range(epoch_size):\n",
    "        if epoch%10==0:\n",
    "            print('epoch %d' % epoch)\n",
    "        for a in range(augment_size):\n",
    "            for i in range(len(inputs)):\n",
    "                x = Variable(inputs[i].reshape(1,2).astype(np.float32))\n",
    "                t = Variable(outputs[i].astype(np.int32))\n",
    "                optimizer.update(model, x, t)\n",
    "        if epoch%10==0:\n",
    "            summarize(model, optimizer, inputs, outputs)\n",
    "\"\"\"        \n",
    "# Main\n",
    "\n",
    "## Test data\n",
    "inputs = np.array([[0., 0.], [0., 1.], [1., 0.], [1., 1.]], dtype=np.float32)\n",
    "and_outputs = np.array([[0], [0], [0], [1]], dtype=np.int32)\n",
    "or_outputs = np.array([[0], [1], [1], [1]], dtype=np.int32)\n",
    "xor_outputs = np.array([[0], [1], [1], [0]], dtype=np.int32)\n",
    "\n",
    "## AND Test --> will learn successfully\n",
    "#and_model = L.Classifier(NN2x2_2links())\n",
    "and_model = NN2x2_2links()\n",
    "optimizer = optimizers.SGD()\n",
    "# do it quicker) optimizer = optimizers.MomentumSGD(lr=0.01, momentum=0.9)\n",
    "optimizer.setup(and_model)\n",
    "print('<<AND: Before learning>>')\n",
    "#summarize(and_model, optimizer, inputs, and_outputs)\n",
    "print('\\n<<AND: After Learning>>')\n",
    "learning_looper(and_model, optimizer, inputs, and_outputs, epoch_size = 21)\n",
    "\n",
    "## OR Test --> will learn successfully\n",
    "#or_model = L.Classifier(NN2x2_2links())\n",
    "or_model = NN2x2_2links()\n",
    "optimizer = optimizers.SGD()\n",
    "optimizer.setup(or_model)\n",
    "print('\\n---------\\n\\n<<OR: Before learning>>')\n",
    "#summarize(or_model, optimizer, inputs, or_outputs)\n",
    "print('\\n<<OR: After Learning>>')\n",
    "learning_looper(or_model, optimizer, inputs, or_outputs, epoch_size = 21)\n",
    "\n",
    "## XOR Test --> will learn successfully\n",
    "xor_model = L.Classifier(NN2x2_2links())\n",
    "#optimizer = optimizers.SGD()\n",
    "optimizer = optimizers.MomentumSGD(lr=0.01, momentum=0.9)\n",
    "optimizer.setup(xor_model)\n",
    "print('\\n---------\\n\\n<<XOR: Before learning>>')\n",
    "#summarize(xor_model, optimizer, inputs, xor_outputs)\n",
    "print('\\n<<XOR: After Learning>>')\n",
    "#XOR_learning_looper(xor_model, optimizer, inputs, xor_outputs, epoch_size = 251)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## こっちでもできます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      " 0 & 0 = 0 (zero:0.878019 one:0.573771)\n",
      " 0 & 1 = 0 (zero:0.718681 one:0.384091)\n",
      " 1 & 0 = 0 (zero:0.658738 one:0.436243)\n",
      " 1 & 1 = 0 (zero:0.514890 one:0.291071)\n",
      "epoch: 100\n",
      " 0 & 0 = 0 (zero:0.767173 one:0.674628)\n",
      " 0 & 1 = 0 (zero:0.545713 one:0.543038)\n",
      " 1 & 0 = 0 (zero:0.522334 one:0.517389)\n",
      " 1 & 1 = 1 (zero:0.348787 one:0.435395)\n",
      "epoch: 200\n",
      " 0 & 0 = 0 (zero:0.823804 one:0.578874)\n",
      " 0 & 1 = 1 (zero:0.498525 one:0.543165)\n",
      " 1 & 0 = 1 (zero:0.433706 one:0.435473)\n",
      " 1 & 1 = 1 (zero:0.271064 one:0.451696)\n",
      "epoch: 300\n",
      " 0 & 0 = 0 (zero:1.005237 one:0.392361)\n",
      " 0 & 1 = 1 (zero:0.425922 one:0.555449)\n",
      " 1 & 0 = 1 (zero:0.292928 one:0.404549)\n",
      " 1 & 1 = 1 (zero:0.180805 one:0.512586)\n",
      "epoch: 400\n",
      " 0 & 0 = 0 (zero:1.377135 one:0.117970)\n",
      " 0 & 1 = 1 (zero:0.335019 one:0.618482)\n",
      " 1 & 0 = 1 (zero:0.164425 one:0.467239)\n",
      " 1 & 1 = 1 (zero:0.105640 one:0.616617)\n",
      "epoch: 500\n",
      " 0 & 0 = 0 (zero:1.745432 one:-0.165976)\n",
      " 0 & 1 = 1 (zero:0.287419 one:0.675842)\n",
      " 1 & 0 = 1 (zero:0.078467 one:0.554091)\n",
      " 1 & 1 = 1 (zero:0.106902 one:0.702316)\n",
      "epoch: 600\n",
      " 0 & 0 = 0 (zero:1.985202 one:-0.372336)\n",
      " 0 & 1 = 1 (zero:0.312151 one:0.704071)\n",
      " 1 & 0 = 1 (zero:0.022154 one:0.658205)\n",
      " 1 & 1 = 1 (zero:0.207343 one:0.754876)\n",
      "epoch: 700\n",
      " 0 & 0 = 0 (zero:2.053382 one:-0.513504)\n",
      " 0 & 1 = 1 (zero:0.327039 one:0.680426)\n",
      " 1 & 0 = 1 (zero:-0.124269 one:0.767208)\n",
      " 1 & 1 = 1 (zero:0.323233 one:0.713087)\n",
      "epoch: 800\n",
      " 0 & 0 = 0 (zero:1.961823 one:-0.611763)\n",
      " 0 & 1 = 1 (zero:0.070450 one:0.664556)\n",
      " 1 & 0 = 1 (zero:-0.319292 one:0.839575)\n",
      " 1 & 1 = 0 (zero:0.505835 one:0.479145)\n",
      "epoch: 900\n",
      " 0 & 0 = 0 (zero:1.977746 one:-0.686021)\n",
      " 0 & 1 = 1 (zero:-0.532876 one:0.937308)\n",
      " 1 & 0 = 1 (zero:-0.560701 one:0.954767)\n",
      " 1 & 1 = 0 (zero:0.990103 one:-0.018762)\n",
      "epoch: 1000\n",
      " 0 & 0 = 0 (zero:2.153647 one:-0.815930)\n",
      " 0 & 1 = 1 (zero:-0.925084 one:1.226582)\n",
      " 1 & 0 = 1 (zero:-0.921380 one:1.224663)\n",
      " 1 & 1 = 0 (zero:1.429306 one:-0.422692)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# 参考元 : http://hi-king.hatenablog.com/entry/2015/06/27/194630\n",
    "\n",
    "import random\n",
    "import argparse\n",
    "import numpy\n",
    "import chainer\n",
    "import chainer.optimizers\n",
    "\n",
    "\n",
    "class SmallClassificationModel(chainer.Chain):\n",
    "    def __init__(self):\n",
    "        super(SmallClassificationModel, self).__init__(\n",
    "            l1 = chainer.links.Linear(2, 2)\n",
    "            )\n",
    "    def _forward(self, x):\n",
    "        h = self.l1(x)\n",
    "        return h\n",
    "\n",
    "    def train(self, x_data, y_data):\n",
    "        x = chainer.Variable(x_data.reshape(1,2).astype(numpy.float32))\n",
    "        y = chainer.Variable(y_data.astype(numpy.int32))\n",
    "        h = self._forward(x)\n",
    "\n",
    "        self.zerograds()\n",
    "        error = chainer.functions.softmax_cross_entropy(h, y)\n",
    "        accuracy = chainer.functions.accuracy(h, y)\n",
    "        error.backward()\n",
    "        optimizer.update()\n",
    "        if epoch%100==0:\n",
    "            print(' %d & %d = %d (zero:%f one:%f)' % (x.data[0,0], x.data[0,1], h.data.argmax(), h.data[0,0], h.data[0,1]))\n",
    "        #print(\"error: {}\".format(error.data[0]))\n",
    "        #print(\"accuracy: {}\".format(accuracy.data))\n",
    "\n",
    "class ClassificationModel(chainer.Chain):\n",
    "    def __init__(self):\n",
    "        super(ClassificationModel, self).__init__(\n",
    "            l1 = chainer.links.Linear(2, 2),\n",
    "            l2 = chainer.links.Linear(2, 2)\n",
    "            )\n",
    "    def _forward(self, x):\n",
    "        h = self.l2(chainer.functions.sigmoid(self.l1(x)))\n",
    "        return h\n",
    "\n",
    "    def train(self, x_data, y_data, epoch):\n",
    "        x = chainer.Variable(x_data.reshape(1,2).astype(numpy.float32))\n",
    "        y = chainer.Variable(y_data.astype(numpy.int32))\n",
    "        h = self._forward(x)\n",
    "\n",
    "        self.zerograds()\n",
    "        error = chainer.functions.softmax_cross_entropy(h, y)\n",
    "        accuracy = chainer.functions.accuracy(h, y)\n",
    "        error.backward()\n",
    "        optimizer.update()\n",
    "        if epoch%100==0:\n",
    "            print(' %d & %d = %d (zero:%f one:%f)' % (x.data[0,0], x.data[0,1], h.data.argmax(), h.data[0,0], h.data[0,1]))\n",
    "\n",
    "class RegressionModel(chainer.Chain):\n",
    "    def __init__(self):\n",
    "        super(RegressionModel, self).__init__(\n",
    "            l1 = chainer.links.Linear(2, 2),\n",
    "            l2 = chainer.links.Linear(2, 1)\n",
    "            )\n",
    "\n",
    "    def _forward(self, x):\n",
    "        h = self.l2(chainer.functions.sigmoid(self.l1(x)))\n",
    "        return h\n",
    "\n",
    "    def train(self, x_data, y_data, epoch):\n",
    "        x = chainer.Variable(x_data.reshape(1,2).astype(numpy.float32))\n",
    "        y = chainer.Variable(y_data.reshape(1,1).astype(numpy.float32))\n",
    "        h = self._forward(x)\n",
    "        self.zerograds()\n",
    "        error = chainer.functions.mean_squared_error(h, y)\n",
    "        error.backward()\n",
    "        optimizer.update()\n",
    "        if epoch%100==0:\n",
    "                print('x: {}  h: {})'.format(x.data, h.data))\n",
    "\n",
    "\n",
    "#model = SmallClassificationModel()     # 層が1つの場合\n",
    "model = ClassificationModel()           # 層が2つの場合\n",
    "#model = RegressionModel()              # 重回帰でやった場合\n",
    "\n",
    "optimizer = chainer.optimizers.MomentumSGD(lr=0.01, momentum=0.9)\n",
    "optimizer.setup(model)\n",
    "\n",
    "data_xor = [\n",
    "    [numpy.array([0,0]), numpy.array([0])],\n",
    "    [numpy.array([0,1]), numpy.array([1])],\n",
    "    [numpy.array([1,0]), numpy.array([1])],\n",
    "    [numpy.array([1,1]), numpy.array([0])],\n",
    "]\n",
    "\n",
    "data_and = [\n",
    "    [numpy.array([0,0]), numpy.array([0])],\n",
    "    [numpy.array([0,1]), numpy.array([0])],\n",
    "    [numpy.array([1,0]), numpy.array([0])],\n",
    "    [numpy.array([1,1]), numpy.array([1])],\n",
    "]\n",
    "\n",
    "data_or = [\n",
    "    [numpy.array([0,0]), numpy.array([0])],\n",
    "    [numpy.array([0,1]), numpy.array([1])],\n",
    "    [numpy.array([1,0]), numpy.array([1])],\n",
    "    [numpy.array([1,1]), numpy.array([1])],\n",
    "]\n",
    "\n",
    "for epoch in range(1001):\n",
    "    if epoch%100==0:\n",
    "        print(\"epoch: %d\" %epoch)\n",
    "    for invec, outvec in data_xor:\n",
    "        model.train(invec, outvec, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
